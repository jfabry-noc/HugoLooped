
{
    
    
    
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
    "pages": [{"date":"2023-04-04","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/pages/about/","summary":"I\u0026rsquo;m a software developer (Python, C#, Groovy) with a background in DevOps (Puppet, K8s, Terraform), networking (FortiNet, Cradlepoint), and systems administration (Active Directory, DNS, DHCP.) I used to blog very regularly for years before giving it up for a while, so we\u0026rsquo;ll see how long it lasts this time. In the meantime, you can also find me at:\n GitHub Mastodon Goodreads WakaTime  ","tags":[],"text":"i\u0026rsquo;m a software developer (python, c#, groovy) with a background in devops (puppet, k8s, terraform), networking (fortinet, cradlepoint), and systems administration (active directory, dns, dhcp.) i used to blog very regularly for years before giving it up for a while, so we\u0026rsquo;ll see how long it lasts this time. in the meantime, you can also find me at:\n github mastodon goodreads wakatime  ","title":"About"},{"date":"2023-04-04","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/back-to-hugo/","summary":"Now I\u0026rsquo;m using Hugo again. Have an image.","tags":[],"text":"now i\u0026rsquo;m using hugo again. have an image.\n","title":"Back to Hugo"},{"date":"2022-09-26","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/decreasing-domains/","summary":"It just dawned on me that I\u0026rsquo;ve finally made good progress in decreasing the number of domains that I own. I\u0026rsquo;ve historically purchased domains on a whim; when I\u0026rsquo;m bored or sitting on a bar stool somewhere, I\u0026rsquo;ll grab my phone and check if random domains that pop into my head are available. While the overwhelming majority of them would be taken, I\u0026rsquo;d occasionally strike upon something that hadn\u0026rsquo;t been snatched up.","tags":[],"text":"it just dawned on me that i\u0026rsquo;ve finally made good progress in decreasing the number of domains that i own. i\u0026rsquo;ve historically purchased domains on a whim; when i\u0026rsquo;m bored or sitting on a bar stool somewhere, i\u0026rsquo;ll grab my phone and check if random domains that pop into my head are available. while the overwhelming majority of them would be taken, i\u0026rsquo;d occasionally strike upon something that hadn\u0026rsquo;t been snatched up. i\u0026rsquo;d typically always buy them\u0026hellip; and then do nothing with them the vast majority of the time. they were basically like icann pokémon.\na little over a year ago, i decided that i would start to let some of my domains lapse through attrition. i turned off automatic renewal and figured that if i didn\u0026rsquo;t come up with a use for a particular domain by the time i started getting alerts about the fact that it was expiring, then i didn\u0026rsquo;t really need it in the first place. at the time i owned 9 domains. to date, i\u0026rsquo;ve let 5 of them expire. 1 was something i used for a skunk works project at my job that ended up becoming fairly critical to their workflow, so i transferred that domain to the company when i left that job. (humorously, i never expensed this domain \u0026ndash; even after it became \u0026ldquo;production\u0026rdquo; \u0026ndash; because it renewed on the same date as laifu.moe, and i didn\u0026rsquo;t want to submit the receipt showing both domains. 😅) that leaves me with:\n this domain. the aforementioned laifu.moe, the domain i\u0026rsquo;ve actually owned the longest, and the only domain i\u0026rsquo;ve ever purchased as a \u0026ldquo;joke\u0026rdquo; and actually done something with. a random domain i bought prior to deciding that i\u0026rsquo;d rather just use looped.network as my primary domain. i\u0026rsquo;m letting this one expire, though it has until next summer.  it\u0026rsquo;s typically been easy for me to justify the expense of domains because i tend to use (relatively) inexpensive tlds. i believe the most expensive domain i\u0026rsquo;ve ever purchased as a .io that was around $40 usd for a year. while tlds which are $10 to $15 a year are a bit more palatable, they still add up when i\u0026rsquo;ve got a large number of them\u0026hellip; and that cost is doing absolutely nothing if i do nothing with the domain. today i\u0026rsquo;d only consider purchasing a domain if i have an immediate use for it; i no longer buy any just because it\u0026rsquo;s a fun name that i want to hold on to. i\u0026rsquo;ve actually had a handful of scenarios where i thought of decent domain names and discovered they were available, but so far i\u0026rsquo;ve been walking the straight and narrow without buying them.\nwhile it\u0026rsquo;s a little silly to keep a domain for a single web page, i don\u0026rsquo;t see myself ditching laifu.moe any time soon since my inner weeb likes it too much. looped.network hosts several websites (like this one) and a few servers/services that i run, so it\u0026rsquo;s also pretty locked in. at this point i think i\u0026rsquo;d have to have something pretty outstanding that i wouldn\u0026rsquo;t just host it on another subdomain of looped.network.\n","title":"Decreasing Domains"},{"date":"2022-09-17","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/manjaro-invalid-corrupt-package/","summary":"As the title alludes to, this morning I tried updating my Pinebook Pro running Manjaro Linux through my normal method:\nsudo pacman -Syu Today, this resulted in an error message about the libibus package:\n warning: could not fully load metadata for package libibus-1.5.26-2 error: failed to prepare transaction (invalid or corrupted package)\n Fun. I first wanted to see if it was really just this package that was causing the problem or if there were other issues.","tags":[],"text":"as the title alludes to, this morning i tried updating my pinebook pro running manjaro linux through my normal method:\nsudo pacman -syu today, this resulted in an error message about the libibus package:\n warning: could not fully load metadata for package libibus-1.5.26-2 error: failed to prepare transaction (invalid or corrupted package)\n fun. i first wanted to see if it was really just this package that was causing the problem or if there were other issues. being a pacman noob, i just used the ui to mark updates to the libibus package as ignored. once i did that, all of the other packages installed successfully. this prompted for a reboot, which i gladly did since i figured i\u0026rsquo;d see if that made any difference. once my laptop was back up and running, though, executing pacman -syu again still gave the same error related to libibus.\nsome searches online showed that a mirror with a bad package could be the problem, so i updated my mirrors via:\nsudo pacman-mirrors -f5 this didn\u0026rsquo;t solve the problem, but the new mirror gave me a different error message:\n error: could not open file /var/lib/pacman/local/libibus-1.5.26-2/desc\n with some more searches online, i saw a few people on the manjaro forums say that simply creating those files was enough to fix similar errors they had with other packages. creating the file above just resulted in an error about a second file being missing, so i ultimately ended up running:\nsudo touch /var/lib/pacman/local/libibus-1.5.26-2/desc sudo touch /var/lib/pacman/local/libibus-1.5.26-2/file now running an update allowed things to progress a little further, but i got a slew of errors complaining about libibus header files (.h) existing on the filesystem. my next less-than-well-thought-out idea was to just remove the package and try installing it fresh. i tried running:\nsudo pacman -r libibus fortunately, manjaro didn\u0026rsquo;t let me do this by telling me that it was a dependency for gnome-shell. yeah, removing that would\u0026rsquo;ve been bad. it was back to searching online. the next tip i stumbled across was to try clearing the pacman cache and then install updates with:\nsudo pacman -scc sudo pacman -syyu this unfortunately gave me the same error about the header files. however, the same forum thread had another recommendation to run:\nsudo pacman -syyu --overwrite \u0026#39;*\u0026#39; curious about exactly what this would do prior to running it, i checked out the man page for pacman:\n bypass file conflict checks and overwrite conflicting files. if the package that is about to be installed contains files that are already installed and match glob, this option will cause all those files to be overwritten. using \u0026ndash;overwrite will not allow overwriting a directory with a file or installing packages with conflicting files and directories. multiple patterns can be specified by separating them with a comma. may be specified multiple times. patterns can be negated, such that files matching them will not be overwritten, by prefixing them with an exclamation mark. subsequent matches will override previous ones. a leading literal exclamation mark or backslash needs to be escaped.\n i took this to mean that instead of complaining about the header files that already existed on the filesystem, it would simply overwrite them since my glob was just * to match anything. i ran this, and sure enough everything was fine.\ni mainly run manjaro on my pinebook pro just because it\u0026rsquo;s such a first class citizen there with tons of support. it\u0026rsquo;s now the default when new pinebook devices ship; back when i got mine it was still coming with debian, though i quickly moved it over after seeing how in love the community was with manjaro. i do find that i run into more random issues like this on manjaro than i do with fedora on my other laptop or debian on my servers, for example, and at times it can be a little frustrating. i didn\u0026rsquo;t really want to spend a chunk of my saturday morning troubleshooting this, for example. but while there seem to be more issues with manjaro, the documentation and community are so good that usually after a little time digging in, the solution can always be found. i\u0026rsquo;ve yet to run into any issue where the current installation was a lost cause forcing me to reinstall the operating system.\n","title":"Fixing Manjaro Linux Invalid Or Corrupt Package Error"},{"date":"2022-09-14","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/ffmpeg-audio-from-video/","summary":"Just a few moments ago I needed to extract the audio component out of a video file into some type of standalone audio file, like .mp3. Since I\u0026rsquo;ve been working with Audacity to record audio, I figured maybe it had some capability for ripping it out of video.\nMy initial searches gave me results like this which quickly made it clear that while this is technically possible, it requires some add-ins that I didn\u0026rsquo;t really want to mess around with.","tags":[],"text":"just a few moments ago i needed to extract the audio component out of a video file into some type of standalone audio file, like .mp3. since i\u0026rsquo;ve been working with audacity to record audio, i figured maybe it had some capability for ripping it out of video.\nmy initial searches gave me results like this which quickly made it clear that while this is technically possible, it requires some add-ins that i didn\u0026rsquo;t really want to mess around with. however, since the add-in mentioned in that video was for ffmpeg, i realized i could just use that directly.\ni didn\u0026rsquo;t have ffmpeg installed, but that was easy enough to rectify on fedora 36.\nsudo dnf install ffmpeg-free then i needed to extract the audio. i first checked how it was encoded in the video with:\nffprobe my_video.mp4 after sifting through the output, i saw that it was encoded as aac:\n stream #0:10x2: audio: aac (mp4a / 0x6134706d), 48000 hz, stereo, s16, 317 kb/s (default)\n rather than that, i wanted to simultaneously re-encode the audio as mp3. another quick search showed me some great resources. ultimately, i ended up doing:\nffmpeg -i my_video.mp4 -q:a 0 -map a bourbon.mp3 as mentioned in the stack overflow post, the -q:a 0 parameter allows for a variable bitrate while while -map a says to ignore everything else except the audio.\njust a few moments later, and my mp3 was successfully encoded.\n","title":"Extracting Audio From Video With FFmpeg"},{"date":"2022-09-10","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/kubectl-symbolic-link-error/","summary":"I recently ran across an interesting error with my development Kubernetes cluster, and while I still have no idea what I may have done to cause it, I at least figured out how to rectify it. As is commonly the case, most of the things I end up deploying to Kubernetes simply log to standard out so that I can view logs with the kubectl logs command. While running this against a particular deployment, though, I received an error:","tags":[],"text":"i recently ran across an interesting error with my development kubernetes cluster, and while i still have no idea what i may have done to cause it, i at least figured out how to rectify it. as is commonly the case, most of the things i end up deploying to kubernetes simply log to standard out so that i can view logs with the kubectl logs command. while running this against a particular deployment, though, i received an error:\n failed to try resolving symlinks\n looking at the details of the error message, it seemed that running a command like:\nkubectl logs -f -n {namespace} {podname} is looking for a symbolic link at the following path:\n/var/log/pods/{namespace}_{pod-uuid}/{namespace}\nthe end file itself seems to be something extremely simple, like a number followed by a .log suffix. in my case, it was 4.log. that symbolic link then points to a file at:\n/var/lib/docker/containers/{uuid}/{uuid}-json.log\nwhere the uuid is the uuid of the container in question.\nnote: the directory above isn’t even viewable without being root, so depending on your setup you may need to use sudo ls to be able to look at what’s there.\ni was able to open the -json.log file and validate that it had the information i needed, so i just had to create the missing symlink. i did that with:\nsudo ln -s /var/lib/docker/containers/{uuid}/{uuid}-json.log 4.log since my shell was already in the /var/log/pods/{namespace}_{pod-uuid}/{namespace} directory, i didn’t need to give the full path to the actual link location, just specify the relative file of 4.log.\nsure enough, after creating this i was able to successfully run kubectl logs against the previously broken pod.\n","title":"kubectl logs Symbolic Link Error"},{"date":"2022-09-07","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/kinit-keytab-fail/","summary":"Lately I\u0026rsquo;ve been working through getting WinRM connectivity working between a Linux container and a bunch of Windows servers. I\u0026rsquo;m using the venerable pywinrm library. It works great, but there was a decent bit of setup for the underlying host to make it work that I had been unfamiliar with; you can\u0026rsquo;t just create a client object, plug in some credentials, and go. A big part of this for my setup was configuring krb5 to be able to speak to Active Directory appropriately.","tags":[],"text":"lately i\u0026rsquo;ve been working through getting winrm connectivity working between a linux container and a bunch of windows servers. i\u0026rsquo;m using the venerable pywinrm library. it works great, but there was a decent bit of setup for the underlying host to make it work that i had been unfamiliar with; you can\u0026rsquo;t just create a client object, plug in some credentials, and go. a big part of this for my setup was configuring krb5 to be able to speak to active directory appropriately.\nmy setup involves a container that runs an ssh server which another, external service actually sshs into in order to execute various pieces of code. so my idea was to take the entrypoint script that configures the ssh server and have it also both:\n create a keytab file. use it to get a tgt. create a cron job to keep it refreshed.  let\u0026rsquo;s pretend the ad account i had been given to use was:\nusername@sub.domain.com\nin my manual testing, this worked fine after i was prompted for the password:\nkinit username@sub.domain.com if you\u0026rsquo;re completely new to this, note that it\u0026rsquo;s actually critical that the domain (more appropriately called the \u0026ldquo;realm\u0026rdquo; in this case) is in all capital letters. if i run this manually by execing my way into a container, i get a tgt just like i\u0026rsquo;d expect. i can view it via:\nklist -e unfortunately, things didn\u0026rsquo;t go smoothly when i tried to use a keytab file. i created one in my entrypoint shell script via a function that runs:\n{  echo \u0026#34;addent -password -p username@sub.domain.com -k 1 -e aes256-cts-hmac-sha1-96\u0026#34;  sleep 1  echo \u0026lt;password\u0026gt;  sleep 1  echo \u0026#34;wkt /file.keytab\u0026#34; } | ktutil \u0026amp;\u0026gt; /dev/null the keytab file is created successfully, but as soon as i try to leverage it with\u0026hellip;\nkinit username@sub.domain.com -kt /file.keytab \u0026hellip;i receive a kerberos preauthentication error. after much confusion and searching around online, i finally found an article that got me on the right track.\nthe article discusses the fact that an assumption is being made under the hood that the salt being used to encrypt the contents of the keytab file is the realm concatenated together with the user\u0026rsquo;s samaccountname (aka \u0026ldquo;shortname\u0026rdquo;). so for my sample account, the salt value would be:\nsub.domain.comusername\nthe problem highlighted by the article is that when you authenticate via the userprincipalname format (e.g.: username@domain.com) rather than the shortname format (e.g.: domain\\username), another assumption is made that the prefix of the upn is the same as the shortname. this is very commonly not the case; in a previous life where i actually was the ad sysadmin, i had shortnames of first initial and last name while the upns were actually firstname dot lastname. so for example, my upn was:\nlooped.network@domain.com\nwhile my samaccountname was:\nlnetwork\nif this type of mismatch happens, you can use -s when running addent to specify the salt. after checking ad, i verified in my current case that the username was the same for both properties\u0026hellip; but that in both places it was completely lowercase. i can\u0026rsquo;t say why it was given to me with the first character capitalized, but after re-trying with username@sub.domain.com, everything was successful. this made sense to me because while ad doesn\u0026rsquo;t care about the username\u0026rsquo;s capitalization when it authenticates (hence why manually running kinit and typing the password worked), using a keytab file means that the wrong salt was given.\n","title":"kinit Fails Only When Using Keytab File"},{"date":"2022-08-20","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/neovim-lsp/","summary":"I had written a few months ago on Medium that I was trying to switch from using VS Code as my main editor to Vim. As I mentioned in that post, I\u0026rsquo;ve used Vim for years now, but never as my \u0026ldquo;main\u0026rdquo; editor for when I need to get serious work done, such as with my job. I also swapped from vanilla Vim to Neovim, which I found to have a few quality of life improvements that I enjoyed.","tags":[],"text":"i had written a few months ago on medium that i was trying to switch from using vs code as my main editor to vim. as i mentioned in that post, i\u0026rsquo;ve used vim for years now, but never as my \u0026ldquo;main\u0026rdquo; editor for when i need to get serious work done, such as with my job. i also swapped from vanilla vim to neovim, which i found to have a few quality of life improvements that i enjoyed. i just couldn\u0026rsquo;t stick with it, though, because i missed the how frequently vs code saved me from myself when i did things like making stupid mistakes that i\u0026rsquo;ve need to debug manually because my editor wasn\u0026rsquo;t telling me about the problems in advance. likewise, i got irritated when i kept having to check things like what parameters i needed to pass to a method or where i defined a particular class manually because i couldn\u0026rsquo;t easily peek them like i can in vs code.\nthat being said, i knew this functionality was possible in neovim (and vim), but i just never bothered to check exactly how. during some initial homework on the matter, it seemed like parts of it were fairly simple while other parts were complicated. ultimately, it turned out that how difficult the process is to set everything up really depends on how difficult you want to make it and how much you want to customize things. i just reproduced the steps i originally followed on my work laptop with my personal laptop to validate my notes prior to making this post, and it probably took me less than 5 minutes.\nplugins and init.vim when i first started with neovim, i quite literally told it to just use what i had already set up with vim as far as configuration and plugins were concerned. i had used pathogen for my vim plugins and had my configuration done in ~/.vimrc. neovim looks for configuration files in ~/.config/nvim, and they can be written in vimscript, lua, or a combination of the two. i initially just had my init.vim file with:\nset runtimepath^=~/.vim runtimepath+=~/.vim/after let \u0026amp;packpath = \u0026amp;runtimepath source ~/.vimrc this was taken straight from the documentation. it worked fine, but i wanted to keep my configs separate in this case. i started my just copying the content of my existing .vimrc file to ~/.config/nvim/init.vim.\nnote: if you\u0026rsquo;re curious, my full neovim configuration is on gitlab.\nnext i wanted a plugin manager. vim-plug seems to be extremely popular and was simple enough to install with the command they provide:\nsh -c \u0026#39;curl -flo \u0026#34;${xdg_data_home:-$home/.local/share}\u0026#34;/nvim/site/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\u0026#39; then i just updated my init.vim with the plugins i wanted to install:\ncall plug#begin(\u0026#39;~/.config/plugged\u0026#39;) plug \u0026#39;https://github.com/joshdick/onedark.vim.git\u0026#39; plug \u0026#39;https://github.com/vim-airline/vim-airline.git\u0026#39; plug \u0026#39;https://github.com/tpope/vim-fugitive.git\u0026#39; plug \u0026#39;https://github.com/pprovost/vim-ps1.git\u0026#39; plug \u0026#39;https://github.com/wakatime/vim-wakatime.git\u0026#39; plug \u0026#39;neovim/nvim-lspconfig\u0026#39; plug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} call plug#end() call plug#begin('~/.config/plugged') and call plug#end() indicate what configuration pertains to vim-plug. the path inside of call plug#begin is where plugins get installed to; i could pick whatever arbitrary location i wanted. plugins can be installed with any valid git link. you can see above that there\u0026rsquo;s a mix of full urls and a shorthand method. i started off by just copying the links for plugins i already used with vim (all of the full github links) and then adding the others as i looked up how to do some additional configuration. more on those later.\nwith init.vim updated, i just needed to close and re-open neovim for everything to apply, followed by running:\n:pluginstall this opens a new pane and shows the progress as the indicated plugins are all installed. what\u0026rsquo;s really cool about this is that i can also use :plugupdate to update my plugins, rather than going to my plugin folder and using git commands to check for them.\nnote on configuration i ultimately ended up doing all of my configuration in vimscript. i would actually prefer to use lua, but most of the examples i found were using vimscript. i also have a fairly lengthy function in my original vim configuration for adding numbers to my tabs that i didn\u0026rsquo;t want to have to rewrite, especially since i wholesale copied it from somewhere online. depending on what you want to do, however, you may end up with a mix of both, especially if you find some examples in vimscript and some in lua. this is entirely possible. just note there can be only one init file, either init.vim or init.lua. if you create both, which is what i initially did, you\u0026rsquo;ll get a warning each time you open neovim and only one of them will be loaded.\nto use init.vim as a base and then also import some lua configuration(s), i created a folder for lua at:\n~/.config/nvim/lua\nin there, i created a file called basic.lua where i had some configuration. then, back in init.vim, i just added the following line to tell it to check this file as well:\nlua require(\u0026#39;basic\u0026#39;) error checking note: i ended up not using the steps below, so if you want to follow along with exactly what i ended up using, there\u0026rsquo;s no need to actually do any of the steps in this section.\nthis is where some options come in to play. astute readers may have noticed the second to last plugin in my vim-plug config was for:\nplug \u0026#39;neovim/nvim-lspconfig\u0026#39; this is for the lsp, or language server protocol. this allows neovim to talk to various language servers and implement whatever functionality they offer. however, it doesn\u0026rsquo;t actually come with any language servers included, so i needed to get those and configure them as needed. for example, i could install pyright from some other source, like npm:\nnpm i -g pyright and then i needed additional configuration to tell neovim about this lsp. the samples were in lua, which is why i initially needed to use lua configuration alongside vimscript:\nrequire\u0026#39;lspconfig\u0026#39;.pyright.setup{} this actually worked for me with respect to error checking. opening up a python file would give me warnings and errors on the fly. however, i didn\u0026rsquo;t get any code completion. i started looking at options for this, but frankly a lot of them seemed pretty involved to set up, and i wanted something relatively simple rather than having to take significant amounts of time configuring my editor any time i use a new machine or want to try out a different language.\ncode completion ultimately, i stumbled onto onto conquer of completion, or coc. i don\u0026rsquo;t know why it took me so long to find as it seems to be insanely popular, but better later than never. one of coc\u0026rsquo;s goals is to be as easy to use as doing the same thing in vs code, and i honestly think they\u0026rsquo;ve nailed it. i first installed it via vim-plug in init.vim:\nplug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} after restarting neovim and running :pluginstall, i could now install language servers straight from neovim by running :cocinstall commands:\n:cocinstall coc-json coc-css coc-html coc-htmldjango coc-pyright after this, i fired up a python file and saw that i had both error checking and code completion. there was just one final step.\nkey mapping given the wide array of key mapping options and customizations that people do, coc doesn\u0026rsquo;t want to make any assumptions about what key mappings are available and which may already be in use. as a result, there are no custom mappings by default. instead, they need to be added to your neovim configuration just like any other mapping changes. however, the project shares a terrific example configuration with some recommended mappings in their documentation. i legitimately just copied the sample into my existing init.vim file. this adds some extremely useful mappings like:\n gd to take me to the declaration for what i\u0026rsquo;m hovering. k to show the documentation for what i\u0026rsquo;m hovering (based on the docstring for python, for example.) ]g to go to the next error/warning and [g to go to the previous one. tab and shift + tab to move through the options in the code completion floating window. enter to select the first item in the code completion floating window. a function to remap ctrl + f and ctrl + b, which are normally page down and page up, to scroll up and down in floating windows but only if one is present.  and tons of other stuff great stuff. i initially spent about 30 minutes just playing around with some throwaway code to test all of the different options and key mappings. it honestly feels super natural and now gives me the same benefits of vs code while allowing me to use a much leaner and more productive editor in neovim.\n","title":"Real Time Error Checking and Code Completion With Neovim"},{"date":"2022-08-14","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/gss-ntlmssp-alpine/","summary":"I recently found myself working on a project which required the GSS-NTLMSSP library. The application is going to be delivered via Kubernetes, so I needed to build a Docker image with this library. The project\u0026rsquo;s build instructions are pretty clear about what the dependencies are, but given that this was going to be a Docker image, I wanted to use Alpine Linux as the base image in order to keep the image size as small as possible.","tags":[],"text":"i recently found myself working on a project which required the gss-ntlmssp library. the application is going to be delivered via kubernetes, so i needed to build a docker image with this library. the project\u0026rsquo;s build instructions are pretty clear about what the dependencies are, but given that this was going to be a docker image, i wanted to use alpine linux as the base image in order to keep the image size as small as possible. the problem with this is that alpine is just different enough to require different dependencies, publish their packages under different names, etc.\ni started off by just doing things manually where i fired up a local docker container running the base docker image and then manually installing each package via apk add {package_name} to make troubleshooting easier. once i had all of the packages from the aforementioned build documentation, i ran ./configure, looked at the errors, figured out which package was missing, installed it, and tried again. after several iterations of this process, ./configure executed successfully and it was time to attempt running make.\nmake ran for a minute but then would error out with:\n undefined reference to \u0026rsquo;libintl_dgettext'\n this seemed odd to me because while running ./configure i had received an error that msgfmt couldn\u0026rsquo;t be found, and i had installed gettext-dev in order to accommodate that. after some additional packages searches, i discovered the musl-libintl library is also available. i attempted to install that but received an error that it was attempting to modify a file controlled by the gettext-dev package. i uninstalled that via apk del gettext-dev and then ran into another error that\u0026ndash;duh\u0026ndash;msgfmt was now missing again. i handled that by just installing the vanilla gettext package, not the -dev version, and then finally everything compiled successfully.\nthe following is the full list of packages that i needed in order to get the build to succeed:\n autoconf automake build-base docbook-xsl doxygen findutils gettext git krb5-dev libwbclient libtool libxml2 libxslt libunistring-dev m4 musl-libintl pkgconfig openssl-dev samba-dev zlib-dev  note that git is included just to clone the repo, and build-base is the meta package i used for compiling c software since just installing something like gcc will not include everything needed.\n","title":"Compiling GSS-NTLMSSP For Alpine Linux"},{"date":"2022-07-31","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/powershell-import-classes-functions/","summary":"I\u0026rsquo;ve recently been working on a project that requires me to use PowerShell. I actually feel relatively fluent in PowerShell since it was my main scripting language for a little over a decade while I worked as a sysadmin in highly Windows-centric environments that involved me automating as much of my job as possible in order to be able to do things like sleep on occasion. However, my PowerShell work rarely (read: never) went beyond single file scripts.","tags":[],"text":"i\u0026rsquo;ve recently been working on a project that requires me to use powershell. i actually feel relatively fluent in powershell since it was my main scripting language for a little over a decade while i worked as a sysadmin in highly windows-centric environments that involved me automating as much of my job as possible in order to be able to do things like sleep on occasion. however, my powershell work rarely (read: never) went beyond single file scripts.\nwith this project being a decent bit more complicated and with the potential for some of the code to be useful in future projects, i wanted to figure out how to actually break things up into useful chunks, just like i would do when writing something in python. fortunately, it wasn\u0026rsquo;t terribly difficult to figure out, though, as is typically the case with powershell, the documentation was a bit wanting. i had to put information together from a few different resource and go through a little trial-and-error to actually figure it out since microsoft can never just seem to give clear, concise examples of anything powershell-related.\nthe first thing i needed to realize is that i wanted to create my files not with a normal .ps1 extension but with a .psm1 extension to indicate that they were powershell modules. only the file that would normally be executed directly has a .ps1 extension. i kind of hate this since it makes things more difficult to test individually; in python, for example, i could just create a main function that executes when:\nif __name__ == \u0026#34;__main__\u0026#34;: then i can add things in main while building it out that are later ignored when the code is called from elsewhere. powershell doesn\u0026rsquo;t offer anything like this, though it\u0026rsquo;s not a huge ordeal. after creating a .psm1 file, it can contain functions, classes, and/or methods. for example, here\u0026rsquo;s a sample file called hellofunc.psm1 with just a function:\nfunction write-hello {  param(  [parameter(mandatory=$true)][string]$name  )   write-output \u0026#34;hello, $name.\u0026#34; } and here\u0026rsquo;s a file called personclass.psm1 with both a class and a couple of methods:\nclass person {  [string]$name  [int]$age   # constructor.  person([string]$name, [int]$age) {  $this.name = $name  $this.age = $age  }   [string]greetperson([string]$preferredgreeting) {  if($preferredgreeting -eq \u0026#34;\u0026#34; -or $null -eq $preferredgreeting) {  $preferredgreeting = \u0026#34;hello\u0026#34;  }  return \u0026#34;$preferredgreeting, $($this.name). i can\u0026#39;t believe you\u0026#39;re $($this.age)years old.\u0026#34;  }   [void]havebirthday() {  $this.age++  } } neither file has an entrypoint, though that\u0026rsquo;s expected since they\u0026rsquo;re designed to be called from somewhere else. here\u0026rsquo;s the main.ps1 file which ties them all together:\n#!/usr/bin/env pwsh using module ./personclass.psm1 using module ./hellofunc.psm1  write-hello -name \u0026#34;garrett\u0026#34;  $me = [person]::new(\u0026#34;garrett\u0026#34;, 9000) write-output $me.greetperson(\u0026#34;salutations\u0026#34;) $me.havebirthday() write-output $me.greetperson(\u0026#34;salutations\u0026#34;) the most important thing here are the two using statements, which specify that i\u0026rsquo;m going to import the two aforementioned files. once i do this, i can then call classes, methods, and functions in those files directly.\n","title":"Importing Functions, Classes, and Methods From Other PowerShell Files"},{"date":"2022-07-05","image":"","imageAlt":"","link":"https://hugolooped.pages.dev/posts/terraform-cloud-variables/","summary":"This post easily falls into the “so ridiculous that it shouldn’t be a post” category. However, considering how long I ended up stuck on it earlier today, I figure it’s worth making if it stands a chance of helping even one other person avoid the same fate as me. 😅\nI’ve started doing a little bit of work with the Terraform Cloud API. Specifically, I was looking at being able to update a workspace variable through code.","tags":[],"text":"this post easily falls into the “so ridiculous that it shouldn’t be a post” category. however, considering how long i ended up stuck on it earlier today, i figure it’s worth making if it stands a chance of helping even one other person avoid the same fate as me. 😅\ni’ve started doing a little bit of work with the terraform cloud api. specifically, i was looking at being able to update a workspace variable through code. in this case, i was trying to change a variable i called replica_count which, if the name wasn’t enough of a giveaway, i was using to track how many replicas should be used in a kubernetes container spec.\ni found that i was able to easily get back all of my workspace variables via a get to:\nhttps://app.terraform.io/api/v2/workspaces/{workspace_id}/vars/ however, trying to make a patch to\u0026hellip;\nhttps://app.terraform.io/api/v2/workspaces/{workspace_id}/vars/{variable_id} \u0026hellip; with a body in json to specify the change resulted in a 500 internal server error response.\nthe json in the body wasn’t very complex. i only needed to modify the value. as the documentation specifies, and the type must be set to “vars” and the id must be set to the id of the variable to change. this is a bit odd to me since i also have to give the id in the url, but it’s not a big deal. the attributes property then can optionally contain whatever property or properties need to be updated. in my case, the json just looked like:\n{ “data”: { “id”: var_id, “type”: “vars”, “attributes”: { “value”: 2 } } } there isn’t a lot to go wrong here\u0026hellip; but i managed to do it! i finally figured out what was wrong when i changed my patch to a get just to validate that my json had to be the culprit. the get responds with json which is very similar to what i needed to send, and that’s what tipped me off to the fact that the value of the variable is always a string, even if i’m thinking of it as a number in my head. so my value line needed to be:\n“value”: “2” after seeing that in the response to my get, i updated my json, re-patched, and saw that everything was successful.\n","title":"https://looped.network/terraform-cloud-variables-are-all-strings"}]
}

